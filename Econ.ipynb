{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Udzf/Israel-Palestine/blob/main/Econ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RZH5RqfJCUVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and load packages"
      ],
      "metadata": {
        "id": "UKCerXvqCQph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install linearmodels\n",
        "!pip install stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3NiQW2YLAim",
        "outputId": "75a4ccbf-9d4e-4a52-b314-303c4a5ae96f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linearmodels\n",
            "  Downloading linearmodels-6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (0.14.4)\n",
            "Collecting mypy-extensions>=0.4 (from linearmodels)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (3.0.11)\n",
            "Collecting pyhdfe>=0.1 (from linearmodels)\n",
            "  Downloading pyhdfe-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting formulaic>=1.0.0 (from linearmodels)\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting setuptools-scm<9.0.0,>=8.0.0 (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels)\n",
            "  Downloading setuptools_scm-8.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.0->linearmodels)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (24.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (75.1.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (2.2.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.0->linearmodels) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->linearmodels) (1.17.0)\n",
            "Downloading linearmodels-6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: setuptools-scm, mypy-extensions, interface-meta, pyhdfe, formulaic, linearmodels\n",
            "Successfully installed formulaic-1.1.1 interface-meta-1.3.0 linearmodels-6.1 mypy-extensions-1.0.0 pyhdfe-0.2.0 setuptools-scm-8.1.0\n",
            "Collecting stargazer\n",
            "  Downloading stargazer-0.0.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading stargazer-0.0.7-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: stargazer\n",
            "Successfully installed stargazer-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from linearmodels.iv import IV2SLS\n",
        "from stargazer.stargazer import Stargazer"
      ],
      "metadata": {
        "id": "CETO9RtcCKpo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "8QcPQd6KCYtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "iqioJ2zQCbec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from github\n",
        "\n",
        "link_replication_file1 = 'https://raw.githubusercontent.com/Udzf/Israel-Palestine/refs/heads/main/replication_file1.csv'\n",
        "link_replication_file2 = 'https://raw.githubusercontent.com/Udzf/Israel-Palestine/refs/heads/main/replication_file2.csv'\n",
        "link_replication_file3 = 'https://raw.githubusercontent.com/Udzf/Israel-Palestine/refs/heads/main/replication_file3.csv'\n",
        "\n",
        "replication_file1 = pd.read_csv(link_replication_file1)\n",
        "replication_file2 = pd.read_csv(link_replication_file2)\n",
        "replication_file3 = pd.read_csv(link_replication_file3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vzjShyc5Ce5c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replication"
      ],
      "metadata": {
        "id": "LHgUcwBRSbx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 1"
      ],
      "metadata": {
        "id": "mgeKNJcASe-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stata code"
      ],
      "metadata": {
        "id": "UuwG2TNCSgVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' STATA CODE\n",
        "************************************************************************\n",
        "** Table 1. News Pressure and the Length of Conflict-related News\n",
        "************************************************************************\n",
        "\n",
        "use \"$dta/replication_file1.dta\", clear\n",
        "\n",
        "* Panel A: Full sample\n",
        "\n",
        "cap drop sample_deriv\n",
        "xi: ivreg daily_woi (length_conflict_news=high_intensity) i.month i.year i.dow, cluster (monthyear)\n",
        "gen sample_deriv=1 if e(sample)\n",
        "\n",
        "reg length_conflict_news high_intensity i.month i.year i.dow  if sample_deriv==1 , vce(cluster monthyear)\n",
        "test  high_intensity\n",
        "test  high_intensity\n",
        "scalar F_cont=r(F)\n",
        "outreg2 using \"$tables/table_1a.xls\", replace ctitle(\"Length conflict news, 1st stage\") keep(high_intensity) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\n",
        "\n",
        "xi: ivreg daily_woi (length_conflict_news = high_intensity) i.month i.year i.dow  , cluster (monthyear)\n",
        "outreg2 using \"$tables/table_1a.xls\", append ctitle(\"NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\n",
        "\n",
        "xi: ivreg daily_woi_nc (length_conflict_news = high_intensity) i.month i.year i.dow , cluster (monthyear)\n",
        "outreg2 using \"$tables/table_1a.xls\", append ctitle(\"Uncorr NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\n",
        "\n",
        "* Panel A: Sample of days with an attack on the same day or the previous day\n",
        "\n",
        "cap drop sample_deriv\n",
        "xi: ivreg daily_woi (length_conflict_news=high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster (monthyear)\n",
        "gen sample_deriv=1 if e(sample)\n",
        "\n",
        "reg length_conflict_news high_intensity i.month i.year i.dow  if sample_deriv==1& (occurrence_t_y==1 | occurrence_pal_t_y ==1) , vce(cluster monthyear)\n",
        "test  high_intensity\n",
        "scalar F_cont=r(F)\n",
        "outreg2 using \"$tables/table_1b.xls\", replace ctitle(\"Length conflict news, 1st stage\") keep(high_intensity) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\n",
        "\n",
        "xi: ivreg daily_woi (length_conflict_news = high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1) , cluster (monthyear)\n",
        "outreg2 using \"$tables/table_1b.xls\", append ctitle(\"NP, 2SLS\") keep(length_conflict_news) nocons label bdec(5) addstat (\"F excl. instr.\", F_cont) dec(3)\n",
        "\n",
        "xi: ivreg daily_woi_nc (length_conflict_news = high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster (monthyear)\n",
        "outreg2 using \"$tables/table_1b.xls\", append ctitle(\"Uncorr NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "QSJQNzJ9Naq9",
        "outputId": "8b36503e-4561-44d0-9701-974b4f193142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' STATA CODE\\n************************************************************************\\n** Table 1. News Pressure and the Length of Conflict-related News\\n************************************************************************\\n\\nuse \"$dta/replication_file1.dta\", clear\\n\\n* Panel A: Full sample\\n\\ncap drop sample_deriv\\nxi: ivreg daily_woi (length_conflict_news=high_intensity) i.month i.year i.dow, cluster (monthyear)\\ngen sample_deriv=1 if e(sample)\\n\\nreg length_conflict_news high_intensity i.month i.year i.dow  if sample_deriv==1 , vce(cluster monthyear)\\ntest  high_intensity\\ntest  high_intensity\\nscalar F_cont=r(F)\\noutreg2 using \"$tables/table_1a.xls\", replace ctitle(\"Length conflict news, 1st stage\") keep(high_intensity) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\\n\\nxi: ivreg daily_woi (length_conflict_news = high_intensity) i.month i.year i.dow  , cluster (monthyear)\\noutreg2 using \"$tables/table_1a.xls\", append ctitle(\"NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\\n\\nxi: ivreg daily_woi_nc (length_conflict_news = high_intensity) i.month i.year i.dow , cluster (monthyear)\\noutreg2 using \"$tables/table_1a.xls\", append ctitle(\"Uncorr NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\\n\\n* Panel A: Sample of days with an attack on the same day or the previous day\\n\\ncap drop sample_deriv\\nxi: ivreg daily_woi (length_conflict_news=high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster (monthyear)\\ngen sample_deriv=1 if e(sample)\\n\\nreg length_conflict_news high_intensity i.month i.year i.dow  if sample_deriv==1& (occurrence_t_y==1 | occurrence_pal_t_y ==1) , vce(cluster monthyear)\\ntest  high_intensity\\nscalar F_cont=r(F)\\noutreg2 using \"$tables/table_1b.xls\", replace ctitle(\"Length conflict news, 1st stage\") keep(high_intensity) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\\n\\nxi: ivreg daily_woi (length_conflict_news = high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1) , cluster (monthyear)\\noutreg2 using \"$tables/table_1b.xls\", append ctitle(\"NP, 2SLS\") keep(length_conflict_news) nocons label bdec(5) addstat (\"F excl. instr.\", F_cont) dec(3)\\n\\nxi: ivreg daily_woi_nc (length_conflict_news = high_intensity) i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster (monthyear)\\noutreg2 using \"$tables/table_1b.xls\", append ctitle(\"Uncorr NP, 2SLS\") keep(length_conflict_news) nocons label bdec(3) addstat (\"F excl. instr.\", F_cont)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code"
      ],
      "metadata": {
        "id": "S2i7cJmSSjq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Table 1: A. Full Sample"
      ],
      "metadata": {
        "id": "utdoF7zqUEy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating models"
      ],
      "metadata": {
        "id": "6L7vUx-hqlVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data table 1\n",
        "# Drop missing values from the relevant columns\n",
        "data_table_1 = replication_file1.copy()\n",
        "relevant_columns = ['daily_woi', 'daily_woi_nc', 'length_conflict_news', 'high_intensity', 'month', 'year', 'dow', 'monthyear']\n",
        "\n",
        "df = data_table_1[relevant_columns].dropna()\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "\n",
        "# Define the first-stage formula\n",
        "first_stage_formula = 'length_conflict_news ~ high_intensity + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the first-stage regression\n",
        "first_stage = smf.ols(first_stage_formula, data=df).fit()\n",
        "\n",
        "# Use the predicted values from the first stage\n",
        "df['length_conflict_news_pred'] = first_stage.predict(df)\n",
        "\n",
        "# Define the second-stage formula (corrected)\n",
        "second_stage_formula_corrected = 'daily_woi ~ length_conflict_news_pred + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the second-stage regression\n",
        "second_stage_corrected = smf.ols(second_stage_formula_corrected, data=df).fit()\n",
        "\n",
        "\n",
        "# Define the second-stage formula\n",
        "second_stage_formula_uncorrected = 'daily_woi_nc ~ length_conflict_news_pred + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the second-stage regression\n",
        "second_stage_uncorrected = smf.ols(second_stage_formula_uncorrected, data=df).fit()\n"
      ],
      "metadata": {
        "id": "OnzyfHfMQGdL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Displaying Table 1: A"
      ],
      "metadata": {
        "id": "I_GXh43XqoQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "stargazer = Stargazer([first_stage, second_stage_corrected, second_stage_uncorrected])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['Intercept', 'high_intensity', 'length_conflict_news_pred'])\n",
        "stargazer.custom_columns([\"Length of Conflict News [2SLS 1st stage]\", \"Corrected News Pressure [2SLS 2nd stage]\", \"Uncorrected News Pressure [2SLS 2nd stage]\"], [1, 1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "cellView": "form",
        "id": "sTdAgSMQRq-e",
        "outputId": "2c2c2ebd-62ac-4cc1-962f-318f104af3be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838f5a506a0>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Length of Conflict News [2SLS 1st stage]</td><td colspan=\"1\">Corrected News Pressure [2SLS 2nd stage]</td><td colspan=\"1\">Uncorrected News Pressure [2SLS 2nd stage]</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
              "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">Intercept</td><td>-2.594<sup>***</sup></td><td>1.150<sup>***</sup></td><td>1.135<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.348)</td><td>(0.034)</td><td>(0.035)</td></tr>\n",
              "<tr><td style=\"text-align:left\">high_intensity</td><td>5.046<sup>***</sup></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.180)</td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">length_conflict_news_pred</td><td></td><td>0.002<sup></sup></td><td>-0.017<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td>(0.004)</td><td>(0.004)</td></tr>\n",
              "\n",
              "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4003</td><td>4003</td><td>4003</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.288</td><td>0.097</td><td>0.116</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.283</td><td>0.091</td><td>0.109</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>2.155 (df=3973)</td><td>0.248 (df=3973)</td><td>0.250 (df=3973)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>55.361<sup>***</sup> (df=29; 3973)</td><td>14.744<sup>***</sup> (df=29; 3973)</td><td>17.934<sup>***</sup> (df=29; 3973)</td></tr>\n",
              "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Table 1: B. Sample of Days with an Attack on the Same Day or the Previous Day"
      ],
      "metadata": {
        "id": "vhcRG_waUNE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating models"
      ],
      "metadata": {
        "id": "QJwcpyuKqtzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data table 1\n",
        "# Drop missing values from the relevant columns\n",
        "data_table_1 = replication_file1.copy()\n",
        "relevant_columns = ['daily_woi', 'daily_woi_nc', 'length_conflict_news', 'high_intensity', 'month', 'year', 'dow', 'monthyear', 'occurrence_t_y', 'occurrence_pal_t_y' ]\n",
        "df = data_table_1[relevant_columns].dropna()\n",
        "\n",
        "# Restrict sample to only include certain observations\n",
        "df = df[(df['occurrence_t_y'] == 1) | (df['occurrence_pal_t_y'] == 1)].copy()\n",
        "\n",
        "# Define the first-stage formula\n",
        "first_stage_formula = 'length_conflict_news ~ high_intensity + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the first-stage regression\n",
        "first_stage = smf.ols(first_stage_formula, data=df).fit()\n",
        "\n",
        "# Use the predicted values from the first stage\n",
        "df['length_conflict_news_pred'] = first_stage.predict(df)\n",
        "\n",
        "# Define the second-stage formula (corrected)\n",
        "second_stage_formula_corrected = 'daily_woi ~ length_conflict_news_pred + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the second-stage regression\n",
        "second_stage_corrected = smf.ols(second_stage_formula_corrected, data=df).fit()\n",
        "\n",
        "\n",
        "# Define the second-stage formula\n",
        "second_stage_formula_uncorrected = 'daily_woi_nc ~ length_conflict_news_pred + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Run the second-stage regression\n",
        "second_stage_uncorrected = smf.ols(second_stage_formula_uncorrected, data=df).fit()\n"
      ],
      "metadata": {
        "id": "iXNgZtjWUM0w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Displaying Table 1:B"
      ],
      "metadata": {
        "id": "tvt9cIu_qxJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "stargazer = Stargazer([first_stage, second_stage_corrected, second_stage_uncorrected])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.covariate_order(['Intercept', 'high_intensity', 'length_conflict_news_pred'])\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.custom_columns([\"Length of Conflict News [2SLS 1st stage]\", \"Corrected News Pressure [2SLS 2nd stage]\", \"Uncorrected News Pressure [2SLS 2nd stage]\"], [1, 1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "cellView": "form",
        "id": "KSKJ4sx3VCVu",
        "outputId": "bb08806f-e5b5-4ea7-9a58-daa301216272"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838f506d150>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Length of Conflict News [2SLS 1st stage]</td><td colspan=\"1\">Corrected News Pressure [2SLS 2nd stage]</td><td colspan=\"1\">Uncorrected News Pressure [2SLS 2nd stage]</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td></tr>\n",
              "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">Intercept</td><td>-2.870<sup>***</sup></td><td>1.141<sup>***</sup></td><td>1.129<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.494)</td><td>(0.039)</td><td>(0.040)</td></tr>\n",
              "<tr><td style=\"text-align:left\">high_intensity</td><td>5.291<sup>***</sup></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.247)</td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">length_conflict_news_pred</td><td></td><td>0.000<sup></sup></td><td>-0.018<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td>(0.004)</td><td>(0.004)</td></tr>\n",
              "\n",
              "<td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>2331</td><td>2331</td><td>2331</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.295</td><td>0.133</td><td>0.156</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.286</td><td>0.123</td><td>0.145</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>2.695 (df=2301)</td><td>0.249 (df=2301)</td><td>0.253 (df=2301)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>33.149<sup>***</sup> (df=29; 2301)</td><td>12.219<sup>***</sup> (df=29; 2301)</td><td>14.681<sup>***</sup> (df=29; 2301)</td></tr>\n",
              "<tr><td colspan=\"4\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"3\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 2"
      ],
      "metadata": {
        "id": "fVokEUzkZcnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stata code"
      ],
      "metadata": {
        "id": "bJr7hYzaZf90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "************************************************************************\n",
        "** Table 2. Coverage of Conflict, News Pressure, and Google Searches\n",
        "************************************************************************\n",
        "\n",
        "use \"$dta/replication_file1.dta\", clear\n",
        "\n",
        "eststo: xi: reg any_conflict_news occurrence_t_y occurrence_pal_t_y i.month i.year i.dow , cluster(monthyear)\n",
        "outreg2 using \"$tables/table_2.xls\", replace ctitle(\"Isr-Pal on news\") keep(occurrence_t_y occurrence_pal_t_y) nocons label bdec(3)\n",
        "\n",
        "eststo: xi: nbreg length_conflict_news occurrence_t_y occurrence_pal_t_y i.month i.year i.dow , vce(cluster monthyear)\n",
        "outreg2 using \"$tables/table_2.xls\", append ctitle(\"Time to Isr-Pal news\") keep(occurrence_t_y occurrence_pal_t_y) nocons label bdec(3)\n",
        "\n",
        "eststo: xi: reg any_conflict_news lnvic_t_y lnvic_pal_y daily_woi i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster(monthyear)\n",
        "outreg2 using \"$tables/table_2.xls\", append ctitle(\"Isr-Pal on news\") keep(lnvic_t_y lnvic_pal_y daily_woi) nocons label bdec(3)\n",
        "\n",
        "eststo: xi: nbreg length_conflict_news lnvic_t_y lnvic_pal_y daily_woi i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), vce(cluster monthyear)\n",
        "outreg2 using \"$tables/table_2.xls\", append ctitle(\"Time to Isr-Pal news\") keep(lnvic_t_y lnvic_pal_y daily_woi) nocons label bdec(3)\n",
        "\n",
        "xi: newey conflict_searches lnvic_t_y lnvic_pal_y monthyear i.month i.year i.dow  if length_conflict_news_t_t_1!=., lag(7) force\n",
        "outreg2 using \"$tables/table_2.xls\", append stats(coef se) keep(lnvic_t_y lnvic_pal_y) nocons label bdec(3)\n",
        "\n",
        "xi: newey conflict_searches lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1  monthyear i.month i.year i.dow  , lag(7) force\n",
        "outreg2 using \"$tables/table_2.xls\", append stats(coef se) keep(lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1) nocons label bdec(3) sdec(3)\n",
        "\n",
        "* Corresponding OLS regressions estimated below to display R-squared\n",
        "eststo: xi: reg conflict_searches lnvic_t_y lnvic_pal_y monthyear i.month i.year i.dow if length_conflict_news_t_t_1!=., vce(cluster monthyear)\n",
        "eststo: xi: reg conflict_searches lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1 monthyear i.month i.year i.dow , vce(cluster monthyear)\n",
        "esttab, se pr2 r2 star(* 0.1 ** 0.05 *** 0.01)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "MgG8nlMcZa7P",
        "outputId": "937e48d1-b41c-468d-98e9-43291cfaca3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n************************************************************************\\n** Table 2. Coverage of Conflict, News Pressure, and Google Searches\\n************************************************************************\\n\\nuse \"$dta/replication_file1.dta\", clear\\n\\neststo: xi: reg any_conflict_news occurrence_t_y occurrence_pal_t_y i.month i.year i.dow , cluster(monthyear)\\noutreg2 using \"$tables/table_2.xls\", replace ctitle(\"Isr-Pal on news\") keep(occurrence_t_y occurrence_pal_t_y) nocons label bdec(3)\\n\\neststo: xi: nbreg length_conflict_news occurrence_t_y occurrence_pal_t_y i.month i.year i.dow , vce(cluster monthyear)\\noutreg2 using \"$tables/table_2.xls\", append ctitle(\"Time to Isr-Pal news\") keep(occurrence_t_y occurrence_pal_t_y) nocons label bdec(3)\\n\\neststo: xi: reg any_conflict_news lnvic_t_y lnvic_pal_y daily_woi i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), cluster(monthyear)\\noutreg2 using \"$tables/table_2.xls\", append ctitle(\"Isr-Pal on news\") keep(lnvic_t_y lnvic_pal_y daily_woi) nocons label bdec(3)\\n\\neststo: xi: nbreg length_conflict_news lnvic_t_y lnvic_pal_y daily_woi i.month i.year i.dow if  (occurrence_t_y==1 | occurrence_pal_t_y ==1), vce(cluster monthyear)\\noutreg2 using \"$tables/table_2.xls\", append ctitle(\"Time to Isr-Pal news\") keep(lnvic_t_y lnvic_pal_y daily_woi) nocons label bdec(3)\\n\\nxi: newey conflict_searches lnvic_t_y lnvic_pal_y monthyear i.month i.year i.dow  if length_conflict_news_t_t_1!=., lag(7) force\\noutreg2 using \"$tables/table_2.xls\", append stats(coef se) keep(lnvic_t_y lnvic_pal_y) nocons label bdec(3)\\n\\nxi: newey conflict_searches lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1  monthyear i.month i.year i.dow  , lag(7) force\\noutreg2 using \"$tables/table_2.xls\", append stats(coef se) keep(lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1) nocons label bdec(3) sdec(3)\\n\\n* Corresponding OLS regressions estimated below to display R-squared\\neststo: xi: reg conflict_searches lnvic_t_y lnvic_pal_y monthyear i.month i.year i.dow if length_conflict_news_t_t_1!=., vce(cluster monthyear)\\neststo: xi: reg conflict_searches lnvic_t_y lnvic_pal_y length_conflict_news_t_t_1 monthyear i.month i.year i.dow , vce(cluster monthyear)\\nesttab, se pr2 r2 star(* 0.1 ** 0.05 *** 0.01)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code"
      ],
      "metadata": {
        "id": "hURl6DDIaUXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creating the models"
      ],
      "metadata": {
        "id": "3H3c64LOqQDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_table_2 = replication_file1.copy()\n",
        "relevant_columns = ['any_conflict_news', 'length_conflict_news', 'month', 'year', 'dow', 'monthyear', 'occurrence_t_y', 'occurrence_pal_t_y' ]\n",
        "data_table_2 = data_table_2[relevant_columns].dropna()\n",
        "\n",
        "\n",
        "data = data_table_2.copy()\n",
        "\n",
        "\n",
        "# First column\n",
        "# Adding interaction terms for categorical variables like i.month, i.year, and i.dow\n",
        "data['month'] = data['month'].astype('category')\n",
        "data['year'] = data['year'].astype('category')\n",
        "data['dow'] = data['dow'].astype('category')\n",
        "\n",
        "# Defining the regression formula\n",
        "formula = \"any_conflict_news ~ occurrence_t_y + occurrence_pal_t_y + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Running the regression with clustering on 'monthyear'\n",
        "model_1 = smf.ols(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['monthyear']})"
      ],
      "metadata": {
        "id": "uA4F6mOOaT4B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second column\n",
        "# Specify that the month, year, and dow variables are categorical\n",
        "data['month'] = data['month'].astype('category')\n",
        "data['year'] = data['year'].astype('category')\n",
        "data['dow'] = data['dow'].astype('category')\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"length_conflict_news ~ occurrence_t_y + occurrence_pal_t_y + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the negative binomial regression model\n",
        "model_2 = smf.negativebinomial(formula, data=data).fit(cov_type='cluster', cov_kwds={'groups': data['monthyear']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z31xFo7_gkcT",
        "outputId": "b463cffa-a87d-4eb6-8e7c-0ec885b3105c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1292: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.758654\n",
            "         Iterations: 35\n",
            "         Function evaluations: 41\n",
            "         Gradient evaluations: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Third column\n",
        "\n",
        "data_table_2 = replication_file1.copy()\n",
        "relevant_columns = ['any_conflict_news', 'daily_woi', 'lnvic_pal_y', 'lnvic_t_y', 'length_conflict_news', 'month', 'year', 'dow', 'monthyear', 'occurrence_t_y', 'occurrence_pal_t_y' ]\n",
        "data_table_2 = data_table_2[relevant_columns].dropna()\n",
        "\n",
        "data = data_table_2.copy()\n",
        "\n",
        "# Filter the data for the specified condition\n",
        "filtered_data = data[(data['occurrence_t_y'] == 1) | (data['occurrence_pal_t_y'] == 1)].copy()\n",
        "\n",
        "# Ensure categorical variables for month, year, and day of the week\n",
        "filtered_data['month'] = filtered_data['month'].astype('category')\n",
        "filtered_data['year'] = filtered_data['year'].astype('category')\n",
        "filtered_data['dow'] = filtered_data['dow'].astype('category')\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"any_conflict_news ~ lnvic_t_y + lnvic_pal_y + daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the linear regression model with clustered standard errors\n",
        "model_3 = smf.ols(formula, data=filtered_data).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['monthyear']})"
      ],
      "metadata": {
        "id": "84Oeg1D8ZlxH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table_2 = replication_file1.copy()\n",
        "relevant_columns = ['any_conflict_news', 'daily_woi', 'lnvic_pal_y', 'lnvic_t_y', 'length_conflict_news', 'month', 'year', 'dow', 'monthyear', 'occurrence_t_y', 'occurrence_pal_t_y' ]\n",
        "data_table_2 = data_table_2[relevant_columns].dropna()\n",
        "\n",
        "data = data_table_2.copy()\n",
        "\n",
        "# Filter the data for the specified condition\n",
        "filtered_data = data[(data['occurrence_t_y'] == 1) | (data['occurrence_pal_t_y'] == 1)].copy()\n",
        "\n",
        "# Ensure categorical variables for month, year, and day of the week\n",
        "filtered_data['month'] = filtered_data['month'].astype('category')\n",
        "filtered_data['year'] = filtered_data['year'].astype('category')\n",
        "filtered_data['dow'] = filtered_data['dow'].astype('category')\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"length_conflict_news ~ lnvic_t_y + lnvic_pal_y + daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the negative binomial regression model with clustered standard errors\n",
        "model_4 = smf.negativebinomial(formula, data=filtered_data).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['monthyear']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GitoWn8QfUQp",
        "outputId": "f71f0d4d-8228-406a-9cdb-7f051dde5f21"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1292: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 1.011429\n",
            "         Iterations: 35\n",
            "         Function evaluations: 64\n",
            "         Gradient evaluations: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 5\n",
        "\n",
        "data_table_2 = replication_file1.copy()\n",
        "relevant_columns = ['length_conflict_news_t_t_1', 'conflict_searches', 'lnvic_pal_y', 'lnvic_t_y',  'month', 'year', 'dow', 'monthyear' ]\n",
        "data_table_2 = data_table_2[relevant_columns].dropna()\n",
        "\n",
        "data = data_table_2.copy()\n",
        "\n",
        "# Filter the data for the specified condition\n",
        "filtered_data = data[data['length_conflict_news_t_t_1'].notnull()]\n",
        "\n",
        "# Ensure categorical variables for month, year, and day of the week\n",
        "filtered_data['month'] = filtered_data['month'].astype('category')\n",
        "filtered_data['year'] = filtered_data['year'].astype('category')\n",
        "filtered_data['dow'] = filtered_data['dow'].astype('category')\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"conflict_searches ~ lnvic_t_y + lnvic_pal_y + monthyear + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the linear regression model with HAC standard errors (lag=7)\n",
        "model_5 = smf.ols(formula, data=filtered_data).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "dpkzVttqhTfP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 6\n",
        "\n",
        "# Ensure categorical variables for month, year, and day of the week\n",
        "data['month'] = data['month'].astype('category')\n",
        "data['year'] = data['year'].astype('category')\n",
        "data['dow'] = data['dow'].astype('category')\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"conflict_searches ~ lnvic_t_y + lnvic_pal_y + length_conflict_news_t_t_1 + monthyear + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the linear regression model with HAC standard errors (lag=7)\n",
        "model_6 = smf.ols(formula, data=data).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "piIPID5Lh_82"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying Table 2"
      ],
      "metadata": {
        "id": "FU-OQMHhqUlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# @ ##### Table 2\n",
        "stargazer = Stargazer([model_1, model_2, model_3, model_4, model_5, model_6])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['occurrence_t_y', 'occurrence_pal_t_y', 'daily_woi', 'lnvic_t_y', 'lnvic_pal_y', 'length_conflict_news_t_t_1'])\n",
        "stargazer.custom_columns([\"Any news (OLS) - all days - 2000-11\", \"Length news (bin) - all days - 2000-11\", \"Any news (OLS) - t/t-1 - 2000-11\", \"Length news (bin) - t/t-1 - 2000-11\", \"Searches (OLS) - all days - 2004-11\", \"Searches (OLS) - all days - 2004-11\"], [1, 1, 1, 1 ,1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "cellView": "form",
        "id": "OhTCsLQ7i9Lo",
        "outputId": "beb4ce22-1509-4792-d43a-294649787397"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838f3ec3310>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">Any news (OLS) - all days - 2000-11</td><td colspan=\"1\">Length news (bin) - all days - 2000-11</td><td colspan=\"1\">Any news (OLS) - t/t-1 - 2000-11</td><td colspan=\"1\">Length news (bin) - t/t-1 - 2000-11</td><td colspan=\"1\">Searches (OLS) - all days - 2004-11</td><td colspan=\"1\">Searches (OLS) - all days - 2004-11</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n",
              "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">occurrence_t_y</td><td>0.100<sup>***</sup></td><td>0.985<sup>***</sup></td><td></td><td></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.020)</td><td>(0.183)</td><td></td><td></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_t_y</td><td>0.112<sup>***</sup></td><td>0.689<sup>***</sup></td><td></td><td></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.032)</td><td>(0.139)</td><td></td><td></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">daily_woi</td><td></td><td></td><td>-0.078<sup>*</sup></td><td>-0.661<sup>***</sup></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.042)</td><td>(0.256)</td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">lnvic_t_y</td><td></td><td></td><td>0.169<sup>***</sup></td><td>0.796<sup>***</sup></td><td>0.130<sup>***</sup></td><td>0.053<sup>*</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.016)</td><td>(0.090)</td><td>(0.043)</td><td>(0.028)</td></tr>\n",
              "<tr><td style=\"text-align:left\">lnvic_pal_y</td><td></td><td></td><td>0.134<sup>***</sup></td><td>0.581<sup>***</sup></td><td>0.042<sup></sup></td><td>0.005<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.024)</td><td>(0.099)</td><td>(0.059)</td><td>(0.054)</td></tr>\n",
              "<tr><td style=\"text-align:left\">length_conflict_news_t_t_1</td><td></td><td></td><td></td><td></td><td></td><td>0.137<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td></td><td>(0.016)</td></tr>\n",
              "\n",
              "<td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4005</td><td>4005</td><td>2331</td><td>2331</td><td>2741</td><td>2741</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.228</td><td></td><td>0.292</td><td></td><td>0.330</td><td>0.376</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.222</td><td></td><td>0.283</td><td></td><td>0.323</td><td>0.370</td></tr><tr><td style=\"text-align: left\">Pseudo R<sup>2</sup></td><td></td><td>0.101</td><td></td><td>0.120</td><td></td><td></td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.340 (df=3974)</td><td>2.384 (df=3974)</td><td>0.376 (df=2299)</td><td>2.754 (df=2299)</td><td>0.554 (df=2714)</td><td>0.534 (df=2713)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>13.196<sup>***</sup> (df=30; 3974)</td><td></td><td>30.134<sup>***</sup> (df=31; 2299)</td><td></td><td>1359.532<sup>***</sup> (df=26; 2714)</td><td>1484.223<sup>***</sup> (df=27; 2713)</td></tr>\n",
              "<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"6\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 3"
      ],
      "metadata": {
        "id": "DbNrfmDR0dqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stata code"
      ],
      "metadata": {
        "id": "frPIpIa-0fzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "*************************************************************************\n",
        "** Table 3. Israeli Attacks and News Pressure\n",
        "************************************************************************\n",
        "\n",
        "use \"$dta/replication_file1.dta\", clear\n",
        "\n",
        "* Panel A: News Pressure\n",
        "\n",
        "sort date\n",
        "\n",
        "xi: reg occurrence daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "outreg2 using \"$tables/table_3a.xls\", replace ctitle(\"Occurrence\") keep(daily_woi) nocons label bdec(3)\n",
        "\n",
        "xi: newey occurrence daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Occurrence\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: newey occurrence daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Occurrence\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: reg lnvic daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi) nocons label bdec(3)\n",
        "\n",
        "xi: newey lnvic daily_woi leaddaily_woi  i.month i.year i.dow if gaza_war==0,lag(7) force\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi leaddaily_woi) nocons label bdec(3)\n",
        "\n",
        "xi: newey lnvic daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: glm victims_isr daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, family(nbinom ml) vce(hac nwest 7)\n",
        "outreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Num. victims\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "* Corresponding OLS regressions estimated below to display (pseudo) R-squared\n",
        "eststo clear\n",
        "eststo: xi: reg occurrence daily_woi i.month i.year i.dow if gaza_war==0 , cluster(monthyear)\n",
        "eststo: xi: reg occurrence daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg occurrence daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: nbreg victims_isr daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, vce(cluster monthyear)\n",
        "esttab, se r2 pr2 star(* 0.10 ** 0.05 *** 0.01)\n",
        "\n",
        "* Panel B: Uncorrected news pressure\n",
        "\n",
        "sort date\n",
        "\n",
        "xi: reg occurrence daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "outreg2 using  \"$tables/table_3b.xls\", replace ctitle(\"Occurrence\") keep(daily_woi_nc) nocons label bdec(3)\n",
        "\n",
        "xi: newey occurrence daily_woi_nc leaddaily_woi_nc  i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using  \"$tables/table_3b.xls\", append ctitle(\"Occurrence\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: newey occurrence daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using \"$tables/table_3b.xls\", append ctitle(\"Occurrence\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: reg lnvic daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "outreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc) nocons label bdec(3)\n",
        "\n",
        "xi: newey lnvic daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0,lag(7) force\n",
        "outreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: newey lnvic daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\n",
        "outreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "xi: glm victims_isr daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, family(nbinom ml) vce(hac nwest 7)\n",
        "outreg2 using \"$tables/table_3b.xls\", append ctitle(\"Num. victims\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\n",
        "\n",
        "* Corresponding OLS regressions estimated below to display (pseudo) R-squared\n",
        "eststo clear\n",
        "eststo: xi: reg occurrence daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg occurrence daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg occurrence daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: xi: reg lnvic daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "eststo: nbreg victims_isr daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\n",
        "esttab, se r2 pr2 star(* 0.10 ** 0.05 *** 0.01) compress\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "dqO6G9yn0fWE",
        "outputId": "d20c4625-4c70-4c79-f3ed-dfdc8c97df59"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n*************************************************************************\\n** Table 3. Israeli Attacks and News Pressure\\n************************************************************************\\n\\nuse \"$dta/replication_file1.dta\", clear\\n\\n* Panel A: News Pressure\\n\\nsort date\\n\\nxi: reg occurrence daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\noutreg2 using \"$tables/table_3a.xls\", replace ctitle(\"Occurrence\") keep(daily_woi) nocons label bdec(3)\\n\\nxi: newey occurrence daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Occurrence\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: newey occurrence daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Occurrence\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: reg lnvic daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi) nocons label bdec(3)\\n\\nxi: newey lnvic daily_woi leaddaily_woi  i.month i.year i.dow if gaza_war==0,lag(7) force\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi leaddaily_woi) nocons label bdec(3)\\n\\nxi: newey lnvic daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: glm victims_isr daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, family(nbinom ml) vce(hac nwest 7)\\noutreg2 using  \"$tables/table_3a.xls\", append ctitle(\"Num. victims\") keep(daily_woi leaddaily_woi lagdaily_woi occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\n* Corresponding OLS regressions estimated below to display (pseudo) R-squared\\neststo clear\\neststo: xi: reg occurrence daily_woi i.month i.year i.dow if gaza_war==0 , cluster(monthyear)\\neststo: xi: reg occurrence daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg occurrence daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi leaddaily_woi i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: nbreg victims_isr daily_woi leaddaily_woi lagdaily_woi-lagdaily_woi7 occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, vce(cluster monthyear)\\nesttab, se r2 pr2 star(* 0.10 ** 0.05 *** 0.01)\\n\\n* Panel B: Uncorrected news pressure\\n\\nsort date\\n\\nxi: reg occurrence daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\noutreg2 using  \"$tables/table_3b.xls\", replace ctitle(\"Occurrence\") keep(daily_woi_nc) nocons label bdec(3)\\n\\nxi: newey occurrence daily_woi_nc leaddaily_woi_nc  i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using  \"$tables/table_3b.xls\", append ctitle(\"Occurrence\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: newey occurrence daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using \"$tables/table_3b.xls\", append ctitle(\"Occurrence\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: reg lnvic daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\noutreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc) nocons label bdec(3)\\n\\nxi: newey lnvic daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0,lag(7) force\\noutreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: newey lnvic daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, lag(7) force\\noutreg2 using \"$tables/table_3b.xls\", append ctitle(\"Ln(victims)\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\nxi: glm victims_isr daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, family(nbinom ml) vce(hac nwest 7)\\noutreg2 using \"$tables/table_3b.xls\", append ctitle(\"Num. victims\") keep(daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14) nocons label bdec(3)\\n\\n* Corresponding OLS regressions estimated below to display (pseudo) R-squared\\neststo clear\\neststo: xi: reg occurrence daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg occurrence daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg occurrence daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi_nc leaddaily_woi_nc i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: xi: reg lnvic daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\neststo: nbreg victims_isr daily_woi_nc leaddaily_woi_nc lagdaily_woi_nc-lagdaily_woi7_nc occurrence_pal_1 occurrence_pal_2_7 occurrence_pal_8_14 i.month i.year i.dow if gaza_war==0, cluster(monthyear)\\nesttab, se r2 pr2 star(* 0.10 ** 0.05 *** 0.01) compress\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python"
      ],
      "metadata": {
        "id": "ycTnNeMF0ln6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating models (corrected news pressure)"
      ],
      "metadata": {
        "id": "c6mn9OFGFPmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 1 models\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "formula = \"occurrence ~ daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_1 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "Z5wXeoT20pZj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war', 'leaddaily_woi']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"occurrence ~ daily_woi + leaddaily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the model using OLS\n",
        "model_2 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})  # Newey-West with 7 lags"
      ],
      "metadata": {
        "id": "9_cq0xhkoa1q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns and drop missing values\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi', 'leaddaily_woi', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi']\n",
        "\n",
        "data_table_3 = data_table_3[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi{lag}'] = filtered_df['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"occurrence ~ daily_woi + leaddaily_woi + lagdaily_woi1 + lagdaily_woi2 + \"\n",
        "           \"lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Fit the model using heteroskedasticity and autocorrelation-consistent (HAC) standard errors\n",
        "model_3 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "XPs_CV-vEKO-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and select relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "# Filter the data based on the condition gaza_war == 0\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = \"lnvic ~ daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_4 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "My8NSM0jFLVO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic', 'daily_woi', 'leaddaily_woi', 'month', 'year', 'dow', 'gaza_war']\n",
        "data_table = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "# Filter data where gaza_war == 0\n",
        "filtered_df = data_table[data_table['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for regression\n",
        "formula = \"lnvic ~ daily_woi + leaddaily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_5 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "QCByggLdHTK3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic','occurrence', 'daily_woi', 'leaddaily_woi', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi']\n",
        "\n",
        "data_table_3 = data_table_3[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi{lag}'] = filtered_df['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"lnvic ~ daily_woi + leaddaily_woi + lagdaily_woi1 + lagdaily_woi2 + \"\n",
        "           \"lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_6 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "ytCMB30wLyKJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_isr', 'occurrence', 'daily_woi', 'leaddaily_woi',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_3 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula for the model\n",
        "formula = (\n",
        "    \"victims_isr ~ daily_woi + leaddaily_woi + \"\n",
        "    \"lagdaily_woi + lagdaily_woi1 + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow) \"\n",
        ")\n",
        "\n",
        "# Fit the Negative Binomial model\n",
        "model_7 = sm.NegativeBinomial.from_formula(formula, data=df_filtered).fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voJ8GKilSlZk",
        "outputId": "3bd8912b-bcad-472e-c4f6-f829bb1a8ee0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 1.319268\n",
            "         Iterations: 35\n",
            "         Function evaluations: 38\n",
            "         Gradient evaluations: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1292: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 1 models\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi_nc', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "formula = \"occurrence ~ daily_woi_nc + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_1_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "J6BuvgM-48J2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi_nc', 'month', 'year', 'dow', 'monthyear', 'gaza_war', 'leaddaily_woi_nc']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"occurrence ~ daily_woi_nc + leaddaily_woi_nc + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the model using OLS\n",
        "model_2_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})  # Newey-West with 7 lags"
      ],
      "metadata": {
        "id": "m3Yd92HB5ZBG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns and drop missing values\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence', 'daily_woi_nc', 'leaddaily_woi_nc', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi']\n",
        "\n",
        "data_table_3 = data_table_3[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi_nc{lag}'] = filtered_df['daily_woi_nc'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"occurrence ~ daily_woi_nc + leaddaily_woi_nc + lagdaily_woi_nc1 + lagdaily_woi_nc2 + \"\n",
        "           \"lagdaily_woi_nc3 + lagdaily_woi_nc4 + lagdaily_woi_nc5 + lagdaily_woi_nc6 + lagdaily_woi_nc7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Fit the model using heteroskedasticity and autocorrelation-consistent (HAC) standard errors\n",
        "model_3_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "mbMA0Lf85gzm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and select relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic', 'daily_woi_nc', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_3 = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "# Filter the data based on the condition gaza_war == 0\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = \"lnvic ~ daily_woi_nc + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_4_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "GEPnZvYz6Dnt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic', 'daily_woi_nc', 'leaddaily_woi_nc', 'month', 'year', 'dow', 'gaza_war']\n",
        "data_table = data_table_3[relevant_columns].dropna()\n",
        "\n",
        "# Filter data where gaza_war == 0\n",
        "filtered_df = data_table[data_table['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for regression\n",
        "formula = \"lnvic ~ daily_woi_nc + leaddaily_woi_nc + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_5_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "V0wM1fnK6M21"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_3 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic','occurrence', 'daily_woi_nc', 'leaddaily_woi_nc', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi_nc']\n",
        "\n",
        "data_table_3 = data_table_3[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi_nc{lag}'] = filtered_df['daily_woi_nc'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"lnvic ~ daily_woi_nc + leaddaily_woi_nc + lagdaily_woi_nc1 + lagdaily_woi_nc2 + \"\n",
        "           \"lagdaily_woi_nc3 + lagdaily_woi_nc4 + lagdaily_woi_nc5 + lagdaily_woi_nc6 + lagdaily_woi_nc7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_6_nc = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "UfvbYoNd6UVw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_isr', 'occurrence', 'daily_woi_nc', 'leaddaily_woi_nc',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'lagdaily_woi_nc'\n",
        "]\n",
        "\n",
        "data_table_3 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_3[data_table_3['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi_nc{lag}'] = df_filtered['daily_woi_nc'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "print(df_filtered.dtypes)\n",
        "\n",
        "# Define the formula for the model\n",
        "formula = (\n",
        "    \"victims_isr ~ daily_woi_nc + leaddaily_woi_nc + \"\n",
        "    \"lagdaily_woi_nc + lagdaily_woi_nc1 + lagdaily_woi_nc2 + lagdaily_woi_nc3 + \"\n",
        "    \"lagdaily_woi_nc4 + lagdaily_woi_nc5 + lagdaily_woi_nc6 + lagdaily_woi_nc7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow) \"\n",
        ")\n",
        "\n",
        "# Fit the Negative Binomial model\n",
        "model_7_nc = sm.NegativeBinomial.from_formula(formula, data=df_filtered).fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxg6pkct6iRJ",
        "outputId": "275a88ad-bf2e-461c-8bff-7fc855ae4647"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "victims_isr             float64\n",
            "occurrence              float64\n",
            "daily_woi_nc            float64\n",
            "leaddaily_woi_nc        float64\n",
            "occurrence_pal_1        float64\n",
            "occurrence_pal_2_7      float64\n",
            "occurrence_pal_8_14     float64\n",
            "month                  category\n",
            "year                   category\n",
            "dow                    category\n",
            "monthyear               float64\n",
            "gaza_war                float64\n",
            "lagdaily_woi_nc         float64\n",
            "lagdaily_woi_nc1        float64\n",
            "lagdaily_woi_nc2        float64\n",
            "lagdaily_woi_nc3        float64\n",
            "lagdaily_woi_nc4        float64\n",
            "lagdaily_woi_nc5        float64\n",
            "lagdaily_woi_nc6        float64\n",
            "lagdaily_woi_nc7        float64\n",
            "dtype: object\n",
            "         Current function value: 1.320865\n",
            "         Iterations: 35\n",
            "         Function evaluations: 39\n",
            "         Gradient evaluations: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1292: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dispalying Table 3"
      ],
      "metadata": {
        "id": "Z5fBjNl6hR39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 3 (corrected news pressure)\n",
        "stargazer = Stargazer([model_1, model_2, model_3, model_4, model_5, model_6, model_7])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['daily_woi', 'leaddaily_woi', 'lagdaily_woi1', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], [1, 1, 1, 1 ,1, 1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "ymXzXk4QQgtJ",
        "outputId": "98f875f9-36df-494d-dcde-e140448c5c61"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838f3f75450>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">1</td><td colspan=\"1\">2</td><td colspan=\"1\">3</td><td colspan=\"1\">4</td><td colspan=\"1\">5</td><td colspan=\"1\">6</td><td colspan=\"1\">7</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td><td>(7)</td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">daily_woi</td><td>0.074<sup>**</sup></td><td>0.030<sup></sup></td><td>0.026<sup></sup></td><td>0.130<sup>**</sup></td><td>0.058<sup></sup></td><td>0.028<sup></sup></td><td>0.045<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.032)</td><td>(0.034)</td><td>(0.035)</td><td>(0.052)</td><td>(0.050)</td><td>(0.046)</td><td>(0.163)</td></tr>\n",
              "<tr><td style=\"text-align:left\">leaddaily_woi</td><td></td><td>0.084<sup>**</sup></td><td>0.078<sup>**</sup></td><td></td><td>0.138<sup>***</sup></td><td>0.121<sup>**</sup></td><td>0.471<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td>(0.033)</td><td>(0.035)</td><td></td><td>(0.047)</td><td>(0.048)</td><td>(0.152)</td></tr>\n",
              "<tr><td style=\"text-align:left\">lagdaily_woi1</td><td></td><td></td><td>-0.028<sup></sup></td><td></td><td></td><td>-0.037<sup></sup></td><td>-3.629<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.034)</td><td></td><td></td><td>(0.045)</td><td>(3.843)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_1</td><td></td><td></td><td>0.104<sup>***</sup></td><td></td><td></td><td>0.220<sup>***</sup></td><td>0.434<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.030)</td><td></td><td></td><td>(0.057)</td><td>(0.111)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_2_7</td><td></td><td></td><td>0.086<sup>***</sup></td><td></td><td></td><td>0.168<sup>***</sup></td><td>0.408<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.021)</td><td></td><td></td><td>(0.036)</td><td>(0.072)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_8_14</td><td></td><td></td><td>0.098<sup>***</sup></td><td></td><td></td><td>0.142<sup>***</sup></td><td>0.294<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.022)</td><td></td><td></td><td>(0.035)</td><td>(0.072)</td></tr>\n",
              "\n",
              "<td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4048</td><td>4045</td><td>4024</td><td>4048</td><td>4045</td><td>4024</td><td>4024</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.181</td><td>0.183</td><td>0.196</td><td>0.175</td><td>0.177</td><td>0.195</td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.175</td><td>0.177</td><td>0.188</td><td>0.169</td><td>0.171</td><td>0.187</td><td></td></tr><tr><td style=\"text-align: left\">Pseudo R<sup>2</sup></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.069</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.443 (df=4018)</td><td>0.442 (df=4014)</td><td>0.439 (df=3983)</td><td>0.635 (df=4018)</td><td>0.634 (df=4014)</td><td>0.625 (df=3983)</td><td>2.877 (df=3982)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>23.171<sup>***</sup> (df=29; 4018)</td><td>28.628<sup>***</sup> (df=30; 4014)</td><td>26.078<sup>***</sup> (df=40; 3983)</td><td>13.660<sup>***</sup> (df=29; 4018)</td><td>19.003<sup>***</sup> (df=30; 4014)</td><td>16.917<sup>***</sup> (df=40; 3983)</td><td></td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"7\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 3 (uncorrected news pressure)\n",
        "stargazer = Stargazer([model_1_nc, model_2_nc, model_3_nc, model_4_nc, model_5_nc, model_6_nc, model_7_nc])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['daily_woi_nc', 'leaddaily_woi_nc', 'lagdaily_woi_nc1', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], [1, 1, 1, 1 ,1, 1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "cellView": "form",
        "id": "KxX8wmfM63VT",
        "outputId": "adf7ced8-fc28-42c1-e333-cc26dbde3632"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838f3f74340>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">1</td><td colspan=\"1\">2</td><td colspan=\"1\">3</td><td colspan=\"1\">4</td><td colspan=\"1\">5</td><td colspan=\"1\">6</td><td colspan=\"1\">7</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td><td>(7)</td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">daily_woi_nc</td><td>0.027<sup></sup></td><td>-0.007<sup></sup></td><td>-0.002<sup></sup></td><td>0.021<sup></sup></td><td>-0.023<sup></sup></td><td>-0.036<sup></sup></td><td>-0.195<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.034)</td><td>(0.034)</td><td>(0.036)</td><td>(0.065)</td><td>(0.053)</td><td>(0.049)</td><td>(0.167)</td></tr>\n",
              "<tr><td style=\"text-align:left\">leaddaily_woi_nc</td><td></td><td>0.063<sup>*</sup></td><td>0.064<sup>*</sup></td><td></td><td>0.080<sup>*</sup></td><td>0.076<sup></sup></td><td>0.326<sup>**</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td>(0.034)</td><td>(0.035)</td><td></td><td>(0.048)</td><td>(0.048)</td><td>(0.154)</td></tr>\n",
              "<tr><td style=\"text-align:left\">lagdaily_woi_nc1</td><td></td><td></td><td>-0.031<sup></sup></td><td></td><td></td><td>-0.032<sup></sup></td><td>-4.954<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.035)</td><td></td><td></td><td>(0.046)</td><td>(4.666)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_1</td><td></td><td></td><td>0.105<sup>***</sup></td><td></td><td></td><td>0.221<sup>***</sup></td><td>0.424<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.030)</td><td></td><td></td><td>(0.056)</td><td>(0.111)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_2_7</td><td></td><td></td><td>0.086<sup>***</sup></td><td></td><td></td><td>0.168<sup>***</sup></td><td>0.407<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.021)</td><td></td><td></td><td>(0.036)</td><td>(0.073)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_8_14</td><td></td><td></td><td>0.099<sup>***</sup></td><td></td><td></td><td>0.145<sup>***</sup></td><td>0.303<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.022)</td><td></td><td></td><td>(0.036)</td><td>(0.072)</td></tr>\n",
              "\n",
              "<td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4048</td><td>4045</td><td>4024</td><td>4048</td><td>4045</td><td>4024</td><td>4024</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.180</td><td>0.181</td><td>0.194</td><td>0.173</td><td>0.174</td><td>0.192</td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.174</td><td>0.175</td><td>0.186</td><td>0.167</td><td>0.167</td><td>0.184</td><td></td></tr><tr><td style=\"text-align: left\">Pseudo R<sup>2</sup></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.068</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.443 (df=4018)</td><td>0.443 (df=4014)</td><td>0.440 (df=3983)</td><td>0.635 (df=4018)</td><td>0.635 (df=4014)</td><td>0.626 (df=3983)</td><td>2.875 (df=3982)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>22.822<sup>***</sup> (df=29; 4018)</td><td>28.275<sup>***</sup> (df=30; 4014)</td><td>25.913<sup>***</sup> (df=40; 3983)</td><td>13.223<sup>***</sup> (df=29; 4018)</td><td>18.763<sup>***</sup> (df=30; 4014)</td><td>16.394<sup>***</sup> (df=40; 3983)</td><td></td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"7\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 4"
      ],
      "metadata": {
        "id": "sjlHhX4Qgygf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code"
      ],
      "metadata": {
        "id": "nPbyXayRg0fS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the models"
      ],
      "metadata": {
        "id": "Mdd_YZjMg2Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 1 models\n",
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence_pal', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_4 = data_table_4[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_4[data_table_4['gaza_war'] == 0]\n",
        "\n",
        "formula = \"occurrence_pal ~ daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_1 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "TT5awinThAxD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence_pal', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war', 'leaddaily_woi']\n",
        "data_table_4 = data_table_4[relevant_columns].dropna()\n",
        "\n",
        "filtered_df = data_table_4[data_table_4['gaza_war'] == 0]\n",
        "\n",
        "# Define the regression formula\n",
        "formula = \"occurrence_pal ~ daily_woi + leaddaily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the model using OLS\n",
        "model_2 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})  # Newey-West with 7 lags"
      ],
      "metadata": {
        "id": "h7da_R2WhsGy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant columns and drop missing values\n",
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['occurrence_pal', 'daily_woi', 'leaddaily_woi', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi']\n",
        "\n",
        "data_table_4 = data_table_4[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi{lag}'] = filtered_df['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"occurrence_pal ~ daily_woi + leaddaily_woi + lagdaily_woi1 + lagdaily_woi2 + \"\n",
        "           \"lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Fit the model using heteroskedasticity and autocorrelation-consistent (HAC) standard errors\n",
        "model_3 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "8DkfRgT6hvu4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and select relevant columns\n",
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic_pal', 'daily_woi', 'month', 'year', 'dow', 'monthyear', 'gaza_war']\n",
        "data_table_4 = data_table_4[relevant_columns].dropna()\n",
        "\n",
        "# Filter the data based on the condition gaza_war == 0\n",
        "filtered_df = data_table_4[data_table_4['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = \"lnvic_pal ~ daily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Fit the regression model with clustered standard errors\n",
        "model_4 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='cluster', cov_kwds={'groups': filtered_df['monthyear']})"
      ],
      "metadata": {
        "id": "A_HmA0vthyw7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic_pal', 'daily_woi', 'leaddaily_woi', 'month', 'year', 'dow', 'gaza_war']\n",
        "data_table = data_table_4[relevant_columns].dropna()\n",
        "\n",
        "# Filter data where gaza_war == 0\n",
        "filtered_df = data_table[data_table['gaza_war'] == 0]\n",
        "\n",
        "# Define the formula for regression\n",
        "formula = \"lnvic_pal ~ daily_woi + leaddaily_woi + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_5 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "QN6OJWCjh4Ff"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy and filter relevant columns\n",
        "data_table_4 = replication_file1.copy()\n",
        "relevant_columns = ['lnvic_pal','occurrence', 'daily_woi', 'leaddaily_woi', \"occurrence_pal_1\",\n",
        "                    \"occurrence_pal_2_7\", \"occurrence_pal_8_14\", 'month', 'year',\n",
        "                    'dow', 'monthyear', 'gaza_war', 'lagdaily_woi']\n",
        "\n",
        "data_table_4 = data_table_4[relevant_columns]\n",
        "\n",
        "# Filter rows where gaza_war == 0 and create a copy\n",
        "filtered_df = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    filtered_df[f'lagdaily_woi{lag}'] = filtered_df['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN values after creating lagged variables\n",
        "filtered_df = filtered_df.dropna()\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = (\"lnvic_pal ~ daily_woi + leaddaily_woi + lagdaily_woi1 + lagdaily_woi2 + \"\n",
        "           \"lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "           \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "           \"C(month) + C(year) + C(dow)\")\n",
        "\n",
        "# Prepare the design matrices for sm.OLS\n",
        "model_6 = smf.ols(formula=formula, data=filtered_df).fit(cov_type='HAC', cov_kwds={'maxlags': 7})"
      ],
      "metadata": {
        "id": "G3NUnp3EiZTg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_pal', 'occurrence', 'daily_woi', 'leaddaily_woi',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula for the model\n",
        "formula = (\n",
        "    \"victims_pal ~ daily_woi + leaddaily_woi + \"\n",
        "    \"lagdaily_woi + lagdaily_woi1 + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow) \"\n",
        ")\n",
        "\n",
        "# Fit the Negative Binomial model\n",
        "model_7 = sm.NegativeBinomial.from_formula(formula, data=df_filtered).fit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v2PPoHzidcG",
        "outputId": "6fd4a19f-14b1-4800-c863-936fc013d5c3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Current function value: 0.309785\n",
            "         Iterations: 35\n",
            "         Function evaluations: 38\n",
            "         Gradient evaluations: 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:1292: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
            "  res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
            "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying Table 4"
      ],
      "metadata": {
        "id": "Y2HkO-JXg4DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 3 (corrected news pressure)\n",
        "stargazer = Stargazer([model_1, model_2, model_3, model_4, model_5, model_6, model_7])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['daily_woi', 'leaddaily_woi', 'lagdaily_woi1', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"], [1, 1, 1, 1 ,1, 1, 1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "cellView": "form",
        "id": "HcmXFy74iiHE",
        "outputId": "f8bb1456-2d48-4579-9970-7009a0a22971"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838e9069f00>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">1</td><td colspan=\"1\">2</td><td colspan=\"1\">3</td><td colspan=\"1\">4</td><td colspan=\"1\">5</td><td colspan=\"1\">6</td><td colspan=\"1\">7</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td><td>(7)</td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">daily_woi</td><td>-0.008<sup></sup></td><td>-0.015<sup></sup></td><td>-0.003<sup></sup></td><td>-0.014<sup></sup></td><td>-0.023<sup></sup></td><td>-0.015<sup></sup></td><td>-0.327<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.013)</td><td>(0.015)</td><td>(0.017)</td><td>(0.016)</td><td>(0.018)</td><td>(0.021)</td><td>(0.429)</td></tr>\n",
              "<tr><td style=\"text-align:left\">leaddaily_woi</td><td></td><td>0.013<sup></sup></td><td>0.019<sup></sup></td><td></td><td>0.017<sup></sup></td><td>0.021<sup></sup></td><td>0.270<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td>(0.018)</td><td>(0.018)</td><td></td><td>(0.019)</td><td>(0.019)</td><td>(0.415)</td></tr>\n",
              "<tr><td style=\"text-align:left\">lagdaily_woi1</td><td></td><td></td><td>-0.023<sup></sup></td><td></td><td></td><td>-0.027<sup></sup></td><td>21.510<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.021)</td><td></td><td></td><td>(0.025)</td><td>(4838.213)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_1</td><td></td><td></td><td>0.020<sup></sup></td><td></td><td></td><td>0.036<sup></sup></td><td>0.190<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.022)</td><td></td><td></td><td>(0.026)</td><td>(0.260)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_2_7</td><td></td><td></td><td>0.012<sup></sup></td><td></td><td></td><td>0.020<sup></sup></td><td>0.256<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.011)</td><td></td><td></td><td>(0.013)</td><td>(0.183)</td></tr>\n",
              "<tr><td style=\"text-align:left\">occurrence_pal_8_14</td><td></td><td></td><td>0.012<sup></sup></td><td></td><td></td><td>0.008<sup></sup></td><td>-0.047<sup></sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.011)</td><td></td><td></td><td>(0.013)</td><td>(0.190)</td></tr>\n",
              "\n",
              "<td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4048</td><td>4045</td><td>4024</td><td>4048</td><td>4045</td><td>4024</td><td>4024</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.088</td><td>0.088</td><td>0.089</td><td>0.085</td><td>0.085</td><td>0.088</td><td></td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.081</td><td>0.081</td><td>0.080</td><td>0.078</td><td>0.078</td><td>0.079</td><td></td></tr><tr><td style=\"text-align: left\">Pseudo R<sup>2</sup></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0.106</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.240 (df=4018)</td><td>0.241 (df=4014)</td><td>0.239 (df=3983)</td><td>0.280 (df=4018)</td><td>0.280 (df=4014)</td><td>0.279 (df=3983)</td><td>0.890 (df=3982)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>8.772<sup>***</sup> (df=29; 4018)</td><td>6.349<sup>***</sup> (df=30; 4014)</td><td>5.201<sup>***</sup> (df=40; 3983)</td><td>7.400<sup>***</sup> (df=29; 4018)</td><td>5.652<sup>***</sup> (df=30; 4014)</td><td>4.706<sup>***</sup> (df=40; 3983)</td><td></td></tr>\n",
              "<tr><td colspan=\"8\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"7\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 5"
      ],
      "metadata": {
        "id": "LGBbTOcYBvfP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stata code"
      ],
      "metadata": {
        "id": "fmh1OV-4Bxhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code"
      ],
      "metadata": {
        "id": "gu3UdawvBzIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating the models"
      ],
      "metadata": {
        "id": "yIsjxDk1gYT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = ['leaddaily_woi', 'lead_maj_events',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'gaza_war', 'monthyear'\n",
        "]\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "filtered_data = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "filtered_data.dropna(inplace=True)\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = \"leaddaily_woi ~ lead_maj_events + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "\n",
        "\n",
        "# Perform the regression with clustered standard errors\n",
        "model_1 = smf.ols(formula, data=filtered_data).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['monthyear']})"
      ],
      "metadata": {
        "id": "KQRte5bFBvTk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 2\n",
        "relevant_columns = ['leaddaily_woi_nc', 'lead_maj_events',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'gaza_war', 'monthyear']\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "filtered_data = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "filtered_data.dropna(inplace=True)\n",
        "\n",
        "# Define the formula for the regression\n",
        "formula = \"leaddaily_woi_nc ~ lead_maj_events + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + C(month) + C(year) + C(dow)\"\n",
        "\n",
        "\n",
        "\n",
        "# Perform the regression with clustered standard errors\n",
        "model_2 = smf.ols(formula, data=filtered_data).fit(cov_type='cluster', cov_kwds={'groups': filtered_data['monthyear']})"
      ],
      "metadata": {
        "id": "rW99on9qEuFC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from linearmodels.iv import IV2SLS\n",
        "import pandas as pd\n",
        "\n",
        "# Column 2\n",
        "relevant_columns = ['leaddaily_woi', 'occurrence', 'lead_maj_events',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'gaza_war', 'monthyear'\n",
        "]\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "filtered_data = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "filtered_data.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# Define dependent variable (y)\n",
        "y = filtered_data['occurrence']\n",
        "\n",
        "# Define endogenous variable (leaddaily_woi)\n",
        "endog = filtered_data['leaddaily_woi']\n",
        "\n",
        "# Define instrument for the endogenous variable (lead_maj_events)\n",
        "instrument = filtered_data['lead_maj_events']\n",
        "\n",
        "# Define exogenous variables (including categorical dummies for month, year, and day of the week)\n",
        "exog = pd.concat([\n",
        "    filtered_data[['occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14']],\n",
        "    pd.get_dummies(filtered_data['month'], prefix='month', drop_first=True),\n",
        "    pd.get_dummies(filtered_data['year'], prefix='year', drop_first=True),\n",
        "    pd.get_dummies(filtered_data['dow'], prefix='dow', drop_first=True)\n",
        "], axis=1)\n",
        "\n",
        "# Perform the IV regression (2SLS)\n",
        "model_3 = IV2SLS(y, exog, endog, instrument).fit(cov_type='clustered', clusters=filtered_data['monthyear'])"
      ],
      "metadata": {
        "id": "3iQKPwFBE_2B"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 4\n",
        "from linearmodels.iv import IV2SLS\n",
        "import pandas as pd\n",
        "\n",
        "# Column 2\n",
        "relevant_columns = ['leaddaily_woi_nc', 'occurrence', 'lead_maj_events',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'gaza_war', 'monthyear'\n",
        "]\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "filtered_data = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "filtered_data.dropna(inplace=True)\n",
        "\n",
        "\n",
        "# Define dependent variable (y)\n",
        "y = filtered_data['occurrence']\n",
        "\n",
        "# Define endogenous variable (leaddaily_woi)\n",
        "endog = filtered_data['leaddaily_woi_nc']\n",
        "\n",
        "# Define instrument for the endogenous variable (lead_maj_events)\n",
        "instrument = filtered_data['lead_maj_events']\n",
        "\n",
        "# Define exogenous variables (including categorical dummies for month, year, and day of the week)\n",
        "exog = pd.concat([\n",
        "    filtered_data[['occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14']],\n",
        "    pd.get_dummies(filtered_data['month'], prefix='month', drop_first=True),\n",
        "    pd.get_dummies(filtered_data['year'], prefix='year', drop_first=True),\n",
        "    pd.get_dummies(filtered_data['dow'], prefix='dow', drop_first=True)\n",
        "], axis=1)\n",
        "\n",
        "# Perform the IV regression (2SLS)\n",
        "model_4 = IV2SLS(y, exog, endog, instrument).fit(cov_type='clustered', clusters=filtered_data['monthyear'])"
      ],
      "metadata": {
        "id": "u3ded_CfIB19"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 5\n",
        "from linearmodels.iv import IV2SLS\n",
        "import pandas as pd\n",
        "\n",
        "# Column 2\n",
        "relevant_columns = ['leaddaily_woi_nc', 'occurrence', 'lead_maj_events',\n",
        "    \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'gaza_war', 'monthyear'\n",
        "]\n",
        "\n",
        "data_table_4 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "filtered_data = data_table_4[data_table_4['gaza_war'] == 0].copy()\n",
        "\n",
        "# Drop rows with NaN due to lagging\n",
        "filtered_data.dropna(inplace=True)\n",
        "\n",
        "formula = \"\"\"\n",
        "occurrence ~ lead_maj_events + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14\n",
        "+ C(month) + C(year) + C(dow)\n",
        "\"\"\"\n",
        "\n",
        "# Perform the regression with clustered standard errors\n",
        "model_5 = smf.ols(formula, data=filtered_data).fit(\n",
        "    cov_type='cluster',\n",
        "    cov_kwds={'groups': filtered_data['monthyear']}\n",
        ")"
      ],
      "metadata": {
        "id": "dKVzEAKXIqf2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Displaying Table 5"
      ],
      "metadata": {
        "id": "P6RAs5z2gMDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 5\n",
        "stargazer = Stargazer([model_1, model_2, model_3, model_4, model_5])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['lead_maj_events', 'leaddaily_woi', 'leaddaily_woi_nc'])\n",
        "# Modify column names with LaTeX formatting and ensure proper rendering\n",
        "stargazer.custom_columns([\"P_t+1 [2SLS 1st stage]\", \"Uncorrected P_t+1 [2SLS 1st stage]\", \"Occurence [2SLS 2nd stage]\", \"Occurence [2SLS 2nd stage]\", \"Occurence [OLS reduced]\"], [1, 1, 1, 1 ,1])\n",
        "\n",
        "stargazer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "iXD76jtXJS27",
        "outputId": "7149a956-1e33-4390-ef36-f0eb0d8c8adf",
        "cellView": "form"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stargazer.stargazer.Stargazer at 0x7838e91a8c40>"
            ],
            "text/html": [
              "Regression Results<br><table style=\"text-align:center\"><tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><tr><td></td><td colspan=\"1\">P_t+1 [2SLS 1st stage]</td><td colspan=\"1\">Uncorrected P_t+1 [2SLS 1st stage]</td><td colspan=\"1\">Occurence [2SLS 2nd stage]</td><td colspan=\"1\">Occurence [2SLS 2nd stage]</td><td colspan=\"1\">Occurence [OLS reduced]</td></tr><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td></tr>\n",
              "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "\n",
              "<tr><td style=\"text-align:left\">lead_maj_events</td><td>0.177<sup>***</sup></td><td>0.190<sup>***</sup></td><td></td><td></td><td>0.109<sup>***</sup></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td>(0.035)</td><td>(0.034)</td><td></td><td></td><td>(0.041)</td></tr>\n",
              "<tr><td style=\"text-align:left\">leaddaily_woi</td><td></td><td></td><td>0.609<sup>***</sup></td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td>(0.233)</td><td></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\">leaddaily_woi_nc</td><td></td><td></td><td></td><td>0.572<sup>***</sup></td><td></td></tr>\n",
              "<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td>(0.210)</td><td></td></tr>\n",
              "\n",
              "<td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
              "<tr><td style=\"text-align: left\">Observations</td><td>4046</td><td>4046</td><td>4046</td><td>4046</td><td>4046</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.117</td><td>0.133</td><td>0.467</td><td>0.466</td><td>0.195</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.110</td><td>0.126</td><td></td><td></td><td>0.189</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>0.244 (df=4013)</td><td>0.246 (df=4013)</td><td>0.428 (df=4014)</td><td>0.427 (df=4014)</td><td>0.439 (df=4013)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>5.402<sup>***</sup> (df=32; 4013)</td><td>6.340<sup>***</sup> (df=32; 4013)</td><td>2190.037<sup>***</sup> (df=32; 4014)</td><td>2116.836<sup>***</sup> (df=32; 4014)</td><td>27.477<sup>***</sup> (df=32; 4013)</td></tr>\n",
              "<tr><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"5\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table 6"
      ],
      "metadata": {
        "id": "atvK_x8ugsma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df = df_filtered.copy()\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df['attacks_target'].unique())\n",
        "\n",
        "df['attacks_target'] = df['attacks_target'].astype('category')\n",
        "df['attacks_target'] = df['attacks_target'].cat.reorder_categories([1, 2,  3], ordered=True)  # Adjust as needed\n",
        "\n",
        "print(df['attacks_target'].unique())\n",
        "\n",
        "# Independent variables\n",
        "independent_vars = [\n",
        "    'leaddaily_woi',\n",
        "    'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14',\n",
        "    'lagdaily_woi', 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4',\n",
        "    'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7'\n",
        "]\n",
        "\n",
        "# Add dummy variables for categorical predictors\n",
        "dummy_vars = pd.get_dummies(df[['month', 'year', 'dow']], drop_first=True)\n",
        "\n",
        "X = pd.concat([df[independent_vars], dummy_vars], axis=1)\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X = X.astype(float)\n",
        "#X = X.apply(pd.to_numeric, errors='coerce')\n",
        "#X = X.astype({col: 'int' for col in X.select_dtypes(include=['bool']).columns})\n",
        "\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['attacks_target']\n",
        "\n",
        "# Fit the multinomial logit model with clustering\n",
        "model = MNLogit(y, X)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df['monthyear']})\n",
        "\n",
        "# Summary of the results\n",
        "print(result.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "6rl4E-5j4tAg",
        "outputId": "3846a593-e7e0-4f56-b579-7af44ccc18a8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3. 1. 2.]\n",
            "[3, 1, 2]\n",
            "Categories (3, int64): [1 < 2 < 3]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MNLogit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-978429810c84>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Fit the multinomial logit model with clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_kwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'monthyear'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MNLogit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_fatal', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df = df_filtered.copy()\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df['attacks_fatal'] = df['attacks_fatal'].astype('category')\n",
        "df['attacks_fatal'] = df['attacks_fatal'].cat.reorder_categories([1, 2,  3], ordered=True)  # Adjust as needed\n",
        "\n",
        "# Independent variables\n",
        "independent_vars = [\n",
        "    'leaddaily_woi',\n",
        "    'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14',\n",
        "    'lagdaily_woi', 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4',\n",
        "    'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7'\n",
        "]\n",
        "\n",
        "# Add dummy variables for categorical predictors\n",
        "dummy_vars = pd.get_dummies(df[['month', 'year', 'dow']], drop_first=True)\n",
        "\n",
        "X = pd.concat([df[independent_vars], dummy_vars], axis=1)\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X = X.astype(int)\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['attacks_fatal']\n",
        "\n",
        "# Fit the multinomial logit model with clustering\n",
        "model = MNLogit(y, X)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df['monthyear']})\n",
        "\n",
        "# Summary of the results\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "Z0gtNgJP5-gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_hpd', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df = df_filtered.copy()\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df['attacks_hpd'] = df['attacks_hpd'].astype('category')\n",
        "df['attacks_hpd'] = df['attacks_hpd'].cat.reorder_categories([1, 2,  3], ordered=True)  # Adjust as needed\n",
        "\n",
        "# Independent variables\n",
        "independent_vars = [\n",
        "    'leaddaily_woi',\n",
        "    'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14',\n",
        "    'lagdaily_woi', 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4',\n",
        "    'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7'\n",
        "]\n",
        "\n",
        "# Add dummy variables for categorical predictors\n",
        "dummy_vars = pd.get_dummies(df[['month', 'year', 'dow']], drop_first=True)\n",
        "\n",
        "X = pd.concat([df[independent_vars], dummy_vars], axis=1)\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X = X.astype(int)\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['attacks_hpd']\n",
        "\n",
        "# Fit the multinomial logit model with clustering\n",
        "model = MNLogit(y, X)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df['monthyear']})\n",
        "\n",
        "# Summary of the results\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "y_N8kOTl_Ncd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_hw', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df = df_filtered.copy()\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df['attacks_hw'] = df['attacks_hw'].astype('category')\n",
        "df['attacks_hw'] = df['attacks_hw'].cat.reorder_categories([1, 2,  3], ordered=True)  # Adjust as needed\n",
        "\n",
        "# Independent variables\n",
        "independent_vars = [\n",
        "    'leaddaily_woi',\n",
        "    'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14',\n",
        "    'lagdaily_woi', 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4',\n",
        "    'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7'\n",
        "]\n",
        "\n",
        "# Add dummy variables for categorical predictors\n",
        "dummy_vars = pd.get_dummies(df[['month', 'year', 'dow']], drop_first=True)\n",
        "\n",
        "X = pd.concat([df[independent_vars], dummy_vars], axis=1)\n",
        "\n",
        "# Add a constant for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "X = X.astype(float)\n",
        "\n",
        "# Define the dependent variable\n",
        "y = df['attacks_hw']\n",
        "\n",
        "# Fit the multinomial logit model with clustering\n",
        "model = MNLogit(y, X)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df['monthyear']})\n",
        "\n",
        "# Summary of the results\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "TcZb8YeN_b48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_non_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define your formula\n",
        "formula = 'victims_non_target ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + C(month) + C(year) + C(dow)'\n",
        "\n",
        "# Fit the GLM model with negative binomial family\n",
        "model = sm.GLM.from_formula(formula, data=df_filtered, family=sm.families.NegativeBinomial()).fit(cov_type='HC0')\n",
        "\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "VKFMd1gGBSuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python code"
      ],
      "metadata": {
        "id": "fuHYsr23guHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "df_filtered = replication_file1[relevant_columns].copy()\n",
        "\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = df_filtered[df_filtered['gaza_war'] == 0].copy()\n",
        "\n",
        "df_filtered['attacks_target'] = df_filtered['attacks_target'].astype('category')\n",
        "\n",
        "print(df_filtered['attacks_target'].cat.categories)\n",
        "\n",
        "# Change the base category for the 'attacks_target' variable\n",
        "df_filtered['attacks_target'] = df_filtered['attacks_target'].cat.reorder_categories(\n",
        "    [1.0, 2.0, 3.0], ordered=True\n",
        ")\n",
        "\n",
        "# Automatically handle the categorical variables\n",
        "df_filtered['month'] = df_filtered['month'].cat.codes\n",
        "df_filtered['year'] = df_filtered['year'].cat.codes\n",
        "df_filtered['dow'] = df_filtered['dow'].cat.codes\n",
        "\n",
        "# Define the formula for multinomial logit regression\n",
        "formula = ('attacks_target ~ leaddaily_woi + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + '\n",
        "           'lagdaily_woi1 + lagdaily_woi2 + lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + '\n",
        "           'C(month) + C(year) + C(dow)')\n",
        "\n",
        "model = smf.mnlogit(formula, data=df_filtered)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df_filtered['monthyear']})\n",
        "\n",
        "# Print the summary of the model\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "Pw44Wpsji4vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi', 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "df_filtered = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df_filtered.dropna(inplace=True)\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = df_filtered[df_filtered['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure 'attacks_target' is a categorical variable\n",
        "df_filtered['attacks_target'] = df_filtered['attacks_target'].astype('category')\n",
        "\n",
        "# Reorder categories and set the base category (e.g., '1.0' as the base)\n",
        "df_filtered['attacks_target'] = df_filtered['attacks_target'].cat.reorder_categories(\n",
        "    [1.0, 2.0, 3.0], ordered=True\n",
        ")\n",
        "\n",
        "# Convert the 'attacks_target' to numeric codes\n",
        "df_filtered['attacks_target'] = df_filtered['attacks_target'].cat.codes\n",
        "\n",
        "# Automatically handle the categorical variables\n",
        "df_filtered['month'] = df_filtered['month'].cat.codes\n",
        "df_filtered['year'] = df_filtered['year'].cat.codes\n",
        "df_filtered['dow'] = df_filtered['dow'].cat.codes\n",
        "\n",
        "# Define the formula for multinomial logit regression\n",
        "formula = ('attacks_target ~ leaddaily_woi + occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + '\n",
        "           'lagdaily_woi1 + lagdaily_woi2 + lagdaily_woi3 + lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + '\n",
        "           'C(month) + C(year) + C(dow)')\n",
        "\n",
        "# Fit the multinomial logit model\n",
        "model = smf.mnlogit(formula, data=df_filtered)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df_filtered['monthyear']})\n",
        "\n",
        "# Print the summary of the model\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "Qa0sdVDCuUgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.outliers_influence as smi\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "X = df_filtered[['leaddaily_woi', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14', 'lagdaily_woi1',\n",
        "                 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4', 'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7',\n",
        "                 'month', 'year', 'dow']]\n",
        "X = add_constant(X)  # Add constant term for VIF calculation\n",
        "\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [smi.variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "id": "UFe0O5A2qG7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.discrete.discrete_model import MNLogit\n",
        "from statsmodels.stats.moment_helpers import cov2corr\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'attacks_fatal', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Ensure the categorical variables are correctly formatted\n",
        "for col in ['month', 'year', 'dow']:\n",
        "    df_filtered[col] = df_filtered[col].astype(str).astype('category')\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "\n",
        "df = df_filtered.copy()\n",
        "\n",
        "df = pd.get_dummies(df, columns=['month', 'year', 'dow'], drop_first=True)\n",
        "\n",
        "# Define independent variables\n",
        "independent_vars = [\n",
        "    'leaddaily_woi',\n",
        "    'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14',\n",
        "    'lagdaily_woi', 'lagdaily_woi2', 'lagdaily_woi3', 'lagdaily_woi4',\n",
        "    'lagdaily_woi5', 'lagdaily_woi6', 'lagdaily_woi7'\n",
        "] + [col for col in df.columns if col.startswith(('month_', 'year_', 'dow_'))]\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Add a constant\n",
        "X = sm.add_constant(df[independent_vars])\n",
        "X = X.astype(float)\n",
        "\n",
        "# Define dependent variable\n",
        "y = df['attacks_fatal']  # Ensure this is encoded as integers\n",
        "\n",
        "model = MNLogit(y, X)\n",
        "result = model.fit(cov_type='cluster', cov_kwds={'groups': df['monthyear']})\n",
        "\n",
        "# Print the summary\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "B-H4Bb9Uo66z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating models"
      ],
      "metadata": {
        "id": "jghArBnNSmLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 2A\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_target ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg2A = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg2A.summary())"
      ],
      "metadata": {
        "id": "11BisJ3_Sl0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column3A\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_non_target', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_non_target ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg3A = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg3A.summary())"
      ],
      "metadata": {
        "id": "CGssPW6eTAkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 2B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'non_fatal_victims', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'occurrence_fatal',  'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[(data_table_6['gaza_war'] == 0) & (data_table_6['occurrence_fatal'] == 0)].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag).copy()\n",
        "\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"non_fatal_victims ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg2B = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg2B.summary())"
      ],
      "metadata": {
        "id": "h20noyAFTtF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 3B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'fatal_victims', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"fatal_victims ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg3B = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg3B.summary())"
      ],
      "metadata": {
        "id": "ePuYfTo5Twy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 3B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_lpd', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_lpd ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg2C = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg2C.summary())"
      ],
      "metadata": {
        "id": "64zT7KH4XgNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 3B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_hpd', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_hpd ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg3C = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg3C.summary())"
      ],
      "metadata": {
        "id": "YisFmZdHXnEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 3B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_nhw', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'occurrence_hw', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[(data_table_6['gaza_war'] == 0) & (data_table_6['occurrence_hw'] == 0)].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_nhw ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg2D = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg2D.summary())"
      ],
      "metadata": {
        "id": "zshhS3SZYE04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Column 3B\n",
        "\n",
        "# Filter relevant columns\n",
        "relevant_columns = [\n",
        "    'victims_hw', \"occurrence_pal_1\", \"occurrence_pal_2_7\", \"occurrence_pal_8_14\",\n",
        "    'month', 'year', 'dow', 'monthyear', 'gaza_war', 'daily_woi' , 'leaddaily_woi' , 'lagdaily_woi'\n",
        "]\n",
        "\n",
        "data_table_6 = replication_file1[relevant_columns].copy()\n",
        "\n",
        "# Filter rows where gaza_war == 0\n",
        "df_filtered = data_table_6[data_table_6['gaza_war'] == 0].copy()\n",
        "\n",
        "# Add lagged variables\n",
        "for lag in range(1, 8):  # Lag from 1 to 7\n",
        "    df_filtered[f'lagdaily_woi{lag}'] = df_filtered['daily_woi'].shift(lag)\n",
        "data_filtered = df_filtered.copy()\n",
        "\n",
        "\n",
        "data_filtered.dropna(inplace=True)\n",
        "\n",
        "# Define the formula using patsy-style syntax\n",
        "formula = (\n",
        "    \"victims_hw ~ leaddaily_woi + lagdaily_woi + lagdaily_woi2 + lagdaily_woi3 + \"\n",
        "    \"lagdaily_woi4 + lagdaily_woi5 + lagdaily_woi6 + lagdaily_woi7 + \"\n",
        "    \"occurrence_pal_1 + occurrence_pal_2_7 + occurrence_pal_8_14 + \"\n",
        "    \"C(month) + C(year) + C(dow)\"\n",
        ")\n",
        "\n",
        "# Fit the GLM with a negative binomial family\n",
        "model_mlneg3D = smf.glm(formula=formula, data=data_filtered, family=sm.families.NegativeBinomial(alpha=1)).fit()\n",
        "\n",
        "# Print the summary with HAC (Newey-West) standard errors\n",
        "print(model_mlneg3D.summary())"
      ],
      "metadata": {
        "id": "f3XiR4RjYIBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Displaying table 6"
      ],
      "metadata": {
        "id": "f2ZlB5wnSoAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 6 (corrected news pressure)\n",
        "stargazer = Stargazer([model_mlneg2A, model_mlneg3A])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['leaddaily_woi', 'lagdaily_woi', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"ML neg (2A)\", \"ML neg (3A)\"], [1,1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "id": "x5gTypGWR2SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 6 (corrected news pressure)\n",
        "stargazer = Stargazer([model_mlneg2B, model_mlneg3B])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['leaddaily_woi', 'lagdaily_woi', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"ML neg (2B)\", \"ML neg (3B)\"], [1,1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "id": "Ufgcg429SP5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 6 (corrected news pressure)\n",
        "stargazer = Stargazer([model_mlneg2C, model_mlneg3C])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['leaddaily_woi', 'lagdaily_woi', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"ML neg (2C)\", \"ML neg (3C)\"], [1,1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "id": "YL1t8OBJYiqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##### Regression Table 6 (corrected news pressure)\n",
        "stargazer = Stargazer([model_mlneg2D, model_mlneg3D])\n",
        "\n",
        "# Customize the output as needed\n",
        "stargazer.title(\"Regression Results\")\n",
        "stargazer.covariate_order(['leaddaily_woi', 'lagdaily_woi', 'occurrence_pal_1', 'occurrence_pal_2_7', 'occurrence_pal_8_14'])\n",
        "stargazer.custom_columns([\"ML neg (2D)\", \"ML neg (3D)\"], [1,1])\n",
        "\n",
        "stargazer"
      ],
      "metadata": {
        "id": "Jgov93RAYl1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension"
      ],
      "metadata": {
        "id": "-SBDmgLm0ro6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data exploration"
      ],
      "metadata": {
        "id": "7aHWagoa0w8-"
      }
    }
  ]
}